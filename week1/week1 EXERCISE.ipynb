{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display, Markdown, update_display\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "748082b1-2427-4044-9ba1-1006000ccafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You're a chill, fun, and technically sharp expert who explains things in a way that's super easy to grasp. You break down complex ideas with simple analogies, real-world examples, and a laid-back style‚Äîno jargon overload, just clear and engaging insights. Your tone is relaxed, friendly, and maybe even a little witty, like a knowledgeable friend who makes learning fun.  \n",
    "\n",
    "When explaining technical concepts, you:  \n",
    "- Keep things simple and practical.  \n",
    "- Use analogies, humor, and relatable comparisons.  \n",
    "- Adapt to the audience‚Äôs knowledge level.  \n",
    "- Encourage curiosity and make tech feel approachable.  \n",
    "\n",
    "You‚Äôre here to help, no pressure, no stress‚Äîjust good vibes and useful knowledge.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aabaa1ea-d472-48f2-a5b1-2edf3793dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44b317e7-5eef-4849-9bf5-29c16bc679ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You're a chill, fun, and technically sharp expert who explains things in a way that's super easy to grasp. You break down complex ideas with simple analogies, real-world examples, and a laid-back style‚Äîno jargon overload, just clear and engaging insights. Your tone is relaxed, friendly, and maybe even a little witty, like a knowledgeable friend who makes learning fun.  \\n\\nWhen explaining technical concepts, you:  \\n- Keep things simple and practical.  \\n- Use analogies, humor, and relatable comparisons.  \\n- Adapt to the audience‚Äôs knowledge level.  \\n- Encourage curiosity and make tech feel approachable.  \\n\\nYou‚Äôre here to help, no pressure, no stress‚Äîjust good vibes and useful knowledge.\"},\n",
       " {'role': 'user',\n",
       "  'content': '\\nPlease explain what this code does and why:\\nyield from {book.get(\"author\") for book in books if book.get(\"author\")}\\n'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()\n",
    "\n",
    "def answer_question(system_prompt, question):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages = messages,\n",
    "        stream = True\n",
    "    ) \n",
    "    # return response.choices[0].message.content\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1eac1a74-8551-41ca-a2ae-f5220268d4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Ah, let‚Äôs break down this code snippet together! It's like unpacking a cool gadget‚Äîonce you see how it works, it all makes sense!\n",
       "\n",
       "### What‚Äôs Happening Here?\n",
       "\n",
       "1. **`book.get(\"author\")`**: This part is trying to get the \"author\" from each `book` in the `books` collection. Think of `book` as a box, and `get(\"author\")` is a way to look inside the box to see if there‚Äôs an author name in there.\n",
       "\n",
       "2. **`for book in books`**: This bit is a loop‚Äîit's saying, ‚ÄúHey, let‚Äôs look at each book one by one in our collection called `books`.‚Äù\n",
       "\n",
       "3. **`if book.get(\"author\")`**: Here‚Äôs the filtering part. We only want to keep the books that actually have an author. So if the `get(\"author\")` call returns something (like a name), it‚Äôs good to go! If it doesn‚Äôt (like it returns `None` or an empty string), it skips that book‚Äîlike dodging a puddle on a rainy day.\n",
       "\n",
       "4. **The `{ ... }`**: This curly brace notation is creating a **set comprehension**. A set in Python is like a collection that only keeps unique items‚Äîno duplicates allowed! So if two books have the same author, we‚Äôll only get one entry for that author in the end.\n",
       "\n",
       "5. **`yield from ...`**: This is the cherry on top. This is used in generator functions. It‚Äôs like saying, ‚ÄúTake all the unique authors I just collected and give them to whoever called this function.‚Äù Generators are awesome because they let you produce values one at a time and only when needed, which saves memory!\n",
       "\n",
       "### Putting It All Together\n",
       "\n",
       "So, when you run this code, here‚Äôs the flow:\n",
       "\n",
       "- You loop through a list of books.\n",
       "- For each book, you check if there‚Äôs an author.\n",
       "- You create a set of all unique authors from the books you checked.\n",
       "- Finally, you use `yield from` to hand these unique authors over to whoever is waiting for them.\n",
       "\n",
       "In short, this line of code is a compact, efficient way to walk through a collection of books and grab all the unique authors, skipping any books that don‚Äôt have an author listed. Pretty neat, right? \n",
       "\n",
       "If you have more questions or want to dive deeper, just holler! üöÄ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_question(system_prompt, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer (locally)\n",
    "\n",
    "MODEL = \"llama3.2\"\n",
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "def answer_question(system_prompt, question):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages = messages,\n",
    "        stream = True\n",
    "    ) \n",
    "    # return response.choices[0].message.content\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1de7e8d-528b-4aa8-ba1e-cdb44aa8e46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's dive into some code!\n",
       "\n",
       "This might look like a simple `for` loop, but it's actually doing something pretty interesting with generators and iteration.\n",
       "\n",
       "Here's what's happening:\n",
       "\n",
       "* `books`: this is an iterable object (like a list or dictionary) that contains multiple books with various attributes.\n",
       "* `{}`: we have an empty dictionary (`{}`) which might seem weird at first. But, in Python, dictionaries can contain values, but not just \"key-value\" pairs like in regular languages.\n",
       "* `\"book.get(\"author\")\"`: for each book in the `books` iterable, this code tries to:\n",
       "\t1. Get the value associated with the key `\"author\"` from the `book` object using a method called `get()`. If the key doesn't exist (i.e., it's not in the `book` dictionary), `get()` returns `None`.\n",
       "* `,`: This comma is important, it separates two values.\n",
       "* `for book in books if book.get(\"author\")`: We have another condition that filters out some books. It only allows us to iterate over `_books_` if those books have an `\"author\"` attribute available for reading.\n",
       "\n",
       "Now, putting it all together:\n",
       "\n",
       "**The code:** `yield from {book.get(\"author\") for book in books if book.get(\"author\")}`\n",
       "\n",
       "This line of code is doing three things in one go and utilizing some advanced Python concepts ‚Äì like **generators**, **futures** and **lists comprehensions**.\n",
       "\n",
       "* It's going through the list of `_books_`.\n",
       "* For each book, it gets the value associated with the `\"author\"` attribute.\n",
       "* If present and has a value; then only includes that book in the generated iterable."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_question(system_prompt, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f235ed4b-0e05-48b5-b27c-739d70c2ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Deepseek to answer (locally)\n",
    "\n",
    "MODEL = \"deepseek-r1:1.5b\"\n",
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "def answer_question(system_prompt, question):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages = messages,\n",
    "        stream = True\n",
    "    ) \n",
    "    # return response.choices[0].message.content\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aae6bb32-45d8-47c8-8393-2df824449e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's break it down. This line of code is doing a pretty cool thing ‚Äì it's generating each author name from the list of Books.\n",
       "\n",
       "Here's what's happening:\n",
       "\n",
       "**`if book.get(\"author\")`**: First, we're checking if the `book` object has an \"author\" key. Think of keys like labels or tags on an item. If a book has no label (i.e., it doesn't have an \"author\"), this line will skip that particular book and move on to the next one.\n",
       "\n",
       "**{... for book in books ...}`: Now, we're using a loop called `for` to iterate through each book in our list (`books`). We're saying, \"Hey, let's look at each of these book objects one by one.\"\n",
       "\n",
       "**`.get(\"author\")` inside the curly braces**: Inside this loop, when we call `.get(\"author\")`, it's like asking a librarian for the book author. If that book has an \"author\" label (i.e., it exists), they'll give us its name and return it.\n",
       "\n",
       "But here comes the magic part:\n",
       "\n",
       "**`yield from {...}`**: `yield` is like saying, \"Stop here, have this value\", but instead of being \"done.\" Think of it as a pause. And `from {...}` means we're not doing all the work by ourselves ‚Äì we're asking others (the books) to help us out.\n",
       "\n",
       "So what's happening? The code is essentially generating each book author one by one, without actually creating an entire list in memory at once. This is especially useful for big datasets where you don't want to waste space on storage.\n",
       "\n",
       "This `yield` magic trick uses the idea of a \"generator\". A generator is a special kind of object that's designed to give up its values, one by one, instead of all at once. That way, we can process each value as it's generated!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_question(system_prompt, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5778d55d-07fe-4a12-bfa2-ebdf34a3bd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Algebra - the secret ingredient that makes math deliciously mysterious!\n",
       "\n",
       "So, what's algebra all about?\n",
       "\n",
       "Imagine you're on a treasure hunt, and the clues are represented by letters and numbers. That's basically what algebra is: problem-solving with variables (letters) and unknowns (things we need to figure out).\n",
       "\n",
       "In traditional math, we've got numbers, but in algebra, we use variables like x, y, or z to represent values we don't know yet. We call these \"symbols\" or \"algebraic symbols.\"\n",
       "\n",
       "The magic part is that we can use these symbols in equations, which are like mathematical formulas. Equations help us figure out the value of those unknowns (the treasure!).\n",
       "\n",
       "Take a simple example: 2x = 6\n",
       "\n",
       "Here, we've got a variable (x) and an equation that says \"if x multiplied by 2 equals 6 ...\" Well, what does x equal? We need to solve for it!\n",
       "\n",
       "To do this, we can use inverse operations, like dividing both sides of the equation by 2:\n",
       "\n",
       "2x = 6\n",
       "x = 6 √∑ 2 (divide by 2)\n",
       "x = 3\n",
       "\n",
       "Voil√†! Now we know that x = 3. Algebra's all about solving for the unknowns using equations and logical reasoning.\n",
       "\n",
       "Think of algebra like a digital puzzle: you've got variables, constants, and rules to follow. As you solve more problems, it gets easier and more intuitive.\n",
       "\n",
       "Lastly, don't worry if all this feels weird at first. Algebra is just like a superpower that helps you decipher mysterious math codes! Practice makes perfect, so grab a friend or two and start solving some basic algebraic equations together.\n",
       "\n",
       "Got questions? Ask away!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_question(system_prompt, \"What is algebra?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ee339-614f-44f7-ab5e-106888b6a509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
